{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4259,"status":"ok","timestamp":1691840909481,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"},"user_tz":-300},"id":"Ie5uLDH4uzAp","outputId":"5b5f6351-8423-4adc-a82f-7e9e342d03c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15921, done.\u001b[K\n","remote: Counting objects: 100% (41/41), done.\u001b[K\n","remote: Compressing objects: 100% (33/33), done.\u001b[K\n","remote: Total 15921 (delta 15), reused 19 (delta 8), pack-reused 15880\u001b[K\n","Receiving objects: 100% (15921/15921), 14.66 MiB | 8.21 MiB/s, done.\n","Resolving deltas: 100% (10910/10910), done.\n","/content/yolov5\n","HEAD is now at fbe67e4 Fix `OMP_NUM_THREADS=1` for macOS (#8624)\n"]}],"source":["# clone YOLOv5 repository\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12363,"status":"ok","timestamp":1691840921835,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"},"user_tz":-300},"id":"wbvMlHd_QwMG","outputId":"65e326b3-a7a1-44a6-dd7e-5c4d680763dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.5/1.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ\u001b[0m \u001b[32m1.5/1.6 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hSetup complete. Using torch 2.0.1+cu118 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15101MB, multi_processor_count=40)\n"]}],"source":["# install dependencies as necessary\n","!pip install -qr requirements.txt  # install dependencies (ignore errors)\n","import torch\n","\n","from IPython.display import Image, clear_output  # to display images\n","from utils.downloads import attempt_download  # to download models/datasets\n","\n","# clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":40595,"status":"ok","timestamp":1691840962423,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"},"user_tz":-300},"id":"Knxi2ncxWffW","outputId":"75b5748b-d27d-4691-af48-526adcae1394"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting roboflow\n","  Downloading roboflow-1.1.2-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi==2022.12.7 (from roboflow)\n","  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n","Collecting cycler==0.10.0 (from roboflow)\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting idna==2.10 (from roboflow)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.4)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy\u003e=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n","Requirement already satisfied: opencv-python\u003e=4.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.76)\n","Requirement already satisfied: Pillow\u003e=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Collecting pyparsing==2.4.7 (from roboflow)\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Collecting supervision (from roboflow)\n","  Downloading supervision-0.13.0-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3\u003e=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.4)\n","Collecting wget (from roboflow)\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.0)\n","Requirement already satisfied: PyYAML\u003e=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (1.1.0)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (4.42.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (23.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eroboflow) (3.2.0)\n","Requirement already satisfied: opencv-python-headless\u003c5.0.0.0,\u003e=4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from supervision-\u003eroboflow) (4.8.0.76)\n","Requirement already satisfied: scipy\u003c2.0.0,\u003e=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision-\u003eroboflow) (1.10.1)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=b63b0591b2c2875ce7c474edd52bbfddd70cec9b6d9548329f13c617db5cebf9\n","  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n","Successfully built wget\n","Installing collected packages: wget, python-dotenv, pyparsing, idna, cycler, certifi, supervision, requests-toolbelt, roboflow\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.1.1\n","    Uninstalling pyparsing-3.1.1:\n","      Successfully uninstalled pyparsing-3.1.1\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.4\n","    Uninstalling idna-3.4:\n","      Successfully uninstalled idna-3.4\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.11.0\n","    Uninstalling cycler-0.11.0:\n","      Successfully uninstalled cycler-0.11.0\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2023.7.22\n","    Uninstalling certifi-2023.7.22:\n","      Successfully uninstalled certifi-2023.7.22\n","Successfully installed certifi-2022.12.7 cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.1.2 supervision-0.13.0 wget-3.2\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","cycler","idna","pyparsing"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["loading Roboflow workspace...\n","loading Roboflow project...\n","Downloading Dataset Version Zip in Uav-7 to yolov5pytorch: 100% [86760366 / 86760366] bytes\n"]},{"name":"stderr","output_type":"stream","text":["Extracting Dataset Version Zip to Uav-7 in yolov5pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10042/10042 [00:02\u003c00:00, 4284.60it/s]\n"]}],"source":["#follow the link below to get your download code from from Roboflow\n","!pip install roboflow\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"fXNvqJubpdjp1mf8IS6s\")\n","project = rf.workspace(\"detection-axsgy\").project(\"uav-ce0zg\")\n","dataset = project.version(7).download(\"yolov5\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1691840962425,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"},"user_tz":-300},"id":"Ug_PhK1oqwQA","outputId":"1e101f4b-55c8-4a22-b448-5e26e6e5941b"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n","names:\n","- bird\n","- drone\n","nc: 2\n","train: Uav-7/train/images\n","val: Uav-7/valid/images\n"]}],"source":["%cd /content/yolov5\n","#after following the link above, recieve python code with these fields filled in\n","#from roboflow import Roboflow\n","#rf = Roboflow(api_key=\"YOUR API KEY HERE\")\n","#project = rf.workspace().project(\"YOUR PROJECT\")\n","#dataset = project.version(\"YOUR VERSION\").download(\"yolov5\")\n","# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n","%cat {dataset.location}/data.yaml"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1691840962426,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"},"user_tz":-300},"id":"dOPn9wjOAwwK"},"outputs":[],"source":["# define number of classes based on YAML\n","import yaml\n","with open(dataset.location + \"/data.yaml\", 'r') as stream:\n","    num_classes = str(yaml.safe_load(stream)['nc'])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1691840962426,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"},"user_tz":-300},"id":"1Rvt5wilnDyX","outputId":"42893e4f-f64f-4ddc-f7ec-e36d2303ea87"},"outputs":[{"name":"stdout","output_type":"stream","text":["# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license\n","\n","# Parameters\n","nc: 80  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 v6.0 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, C3, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 6, C3, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, C3, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 3, C3, [1024]],\n","   [-1, 1, SPPF, [1024, 5]],  # 9\n","  ]\n","\n","# YOLOv5 v6.0 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, C3, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]\n"]}],"source":["#this is the model configuration we will use for our tutorial\n","%cat //content/yolov5/models/yolov5s.yaml"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1691840962427,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"},"user_tz":-300},"id":"t14hhyqdmw6O"},"outputs":[],"source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1691840963110,"user":{"displayName":"misha uroojkhan","userId":"10852817853753218320"},"user_tz":-300},"id":"uDxebz13RdRA"},"outputs":[],"source":["%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n","\n","# parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, BottleneckCSP, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, BottleneckCSP, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, BottleneckCSP, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/medium)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1NcFxRcFdJ_O"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/yolov5\n","2023-08-12 11:46:17.501762: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-08-12 11:46:18.389903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=./models/custom_yolov5s.yaml, data=/content/yolov5/Uav-7/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=1000, batch_size=-1, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=50, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 574 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n","YOLOv5 üöÄ v6.1-306-gfbe67e4 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights \u0026 Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 üöÄ runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00\u003c00:00, 40.1MB/s]\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n","  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","custom_YOLOv5s summary: 283 layers, 7257791 parameters, 7257791 gradients, 16.9 GFLOPs\n","\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 320\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.75G total, 0.21G reserved, 0.05G allocated, 14.48G free\n","      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n","     7257791       4.231         0.275         86.89         213.5        (1, 3, 320, 320)                    list\n","     7257791       8.462         0.185         18.91         43.41        (2, 3, 320, 320)                    list\n","     7257791       16.92         0.287         16.01         39.35        (4, 3, 320, 320)                    list\n","     7257791       33.85         0.501         16.74         42.38        (8, 3, 320, 320)                    list\n","     7257791        67.7         0.921         22.17         50.57       (16, 3, 320, 320)                    list\n","\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 270 for CUDA:0 13.00G/14.75G (88%) ‚úÖ\n","Scaled weight_decay = 0.002109375\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight (no decay), 70 weight, 62 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5/Uav-7/train/labels' images and labels...4386 found, 0 missing, 0 empty, 0 corrupt: 100% 4386/4386 [00:02\u003c00:00, 1858.65it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/Uav-7/train/labels.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.3GB ram): 100% 4386/4386 [00:11\u003c00:00, 382.23it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-7/valid/labels' images and labels...415 found, 0 missing, 0 empty, 0 corrupt: 100% 415/415 [00:00\u003c00:00, 600.97it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/Uav-7/valid/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 415/415 [00:06\u003c00:00, 61.27it/s]\n","Plotting labels to runs/train/yolov5s_results/labels.jpg... \n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.72 anchors/target, 0.973 Best Possible Recall (BPR). Anchors are a poor fit to dataset ‚ö†Ô∏è, attempting to improve...\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING: Extremely small objects found: 220 of 8811 labels are \u003c 3 pixels in size\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 8811 points...\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7305: 100% 1000/1000 [00:02\u003c00:00, 435.99it/s]\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.25: 0.9982 best possible recall, 3.70 anchors past thr\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=320, metric_all=0.269/0.731-mean/best, past_thr=0.524-mean: 4,6, 10,14, 26,30, 55,58, 111,76, 142,164, 280,133, 282,187, 250,241\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ‚úÖ (optional: update model *.yaml to use these anchors in the future)\n","Image sizes 320 train, 320 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/train/yolov5s_results\u001b[0m\n","Starting training for 1000 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     0/999     14.8G    0.1025   0.01945   0.02273       194       320: 100% 17/17 [00:25\u003c00:00,  1.48s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:05\u003c00:00,  5.32s/it]\n","                 all        415        876   0.000956      0.175    0.00148   0.000341\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     1/999     14.2G    0.0964   0.02025   0.01422       201       320: 100% 17/17 [00:19\u003c00:00,  1.13s/it]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 1/1 [00:04\u003c00:00,  4.88s/it]\n","                 all        415        876   0.000438      0.189    0.00142   0.000326\n","\n","     Epoch   gpu_mem       box       obj       cls    labels  img_size\n","     2/999     14.2G   0.09599   0.02036     0.013       890       320:  18% 3/17 [00:02\u003c00:13,  1.07it/s]"]}],"source":[" # train yolov5s on custom data for 100 epochs\n","# time its performance\n","%%time\n","%cd /content/yolov5/\n","!python train.py --img 320 --batch -1 --epochs 1000 --data {dataset.location}/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache --patience 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bOy5KI2ncnWd"},"outputs":[],"source":["# Start tensorboard\n","# Launch after you have started training\n","# logs save in the folder \"runs\"\n","%load_ext tensorboard\n","%tensorboard --logdir runs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C60XAsyv6OPe"},"outputs":[],"source":["# we can also output some older school graphs if the tensor board isn't working for whatever reason...\n","from utils.plots import plot_results  # plot results.txt as results.png\n","Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)  # view results.png"]},{"cell_type":"markdown","metadata":{"id":"N3qM6T0W53gh"},"source":["#Run Inference  With Trained Weights\n","Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIEwt5YLeQ7P"},"outputs":[],"source":["# trained weights are saved by default in our weights folder\n","%ls runs/\n","%ls runs/train/yolov5s_results/weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nmZZnWOgJ2S"},"outputs":[],"source":["# when we ran this, we saw .007 second inference time. That is 140 FPS on a TESLA P100!\n","# use the best weights!\n","%cd /content/yolov5/\n","#!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source /content/yolov5/MultiUav-2/test/images\n","!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source /content/yolov5/Uav-7/test/images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXE9Ao_YVfgD"},"outputs":[],"source":["##I have created a zip file:\n","\n","!zip -r /content/Yolov5s_baseline_FeatureNet_birds_drones.zip /content/yolov5/runs/\n","##Than I have downloded that zip file:\n","!zip -r /content/Yolov5s_baseline_FeatureNet_birds_drones.zip /content/yolov5/runs/detect/\n","##Than I have downloded that zip file:\n","from google.colab import files\n","files.download(\"/content/Yolov5s_baseline_FeatureNet_birds_drones.zip\")"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","provenance":[{"file_id":"1ZSGNy_omEoB5Tk6_rbezbPqYfBtX5Jp5","timestamp":1667999229827},{"file_id":"1KkXMSyMjtSQElofIhag5TNAADrfxHQVl","timestamp":1666939344401},{"file_id":"1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ","timestamp":1663654249868},{"file_id":"https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb","timestamp":1591755516488}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}