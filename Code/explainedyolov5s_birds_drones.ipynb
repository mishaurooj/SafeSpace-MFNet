{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KS9U-kXSNsD",
        "outputId": "331cd94b-ef11-4e0b-a42c-81995a554465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3fP93A7SL3b",
        "outputId": "a3a0b174-9606-4d3a-ef60-275ffb8ab5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14906, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 14906 (delta 11), reused 13 (delta 2), pack-reused 14880\u001b[K\n",
            "Receiving objects: 100% (14906/14906), 13.87 MiB | 22.84 MiB/s, done.\n",
            "Resolving deltas: 100% (10256/10256), done.\n",
            "/content/yolov5\n",
            "HEAD is now at fbe67e4 Fix `OMP_NUM_THREADS=1` for macOS (#8624)\n"
          ]
        }
      ],
      "source": [
        "# clone YOLOv5 repository\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "09a8a884-8f21-4898-a0af-262f417b433a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71 kB 19.0 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 112 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 122 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 133 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 143 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 153 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 163 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 174 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 184 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 194 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 204 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 215 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 225 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 235 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 245 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 256 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 266 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 276 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 286 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 296 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 307 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 317 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 327 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 337 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 348 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 358 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 368 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 378 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 389 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 399 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 409 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 419 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 430 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 440 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 450 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 460 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 471 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 481 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 491 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 501 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 512 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 522 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 532 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 542 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 552 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 563 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 573 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 583 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 593 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 604 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 614 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 624 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 634 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 645 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 655 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 665 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 675 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 686 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 696 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 706 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 716 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 727 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 737 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 747 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 757 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 768 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 778 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 788 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 798 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 808 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 819 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 829 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 839 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 849 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 860 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 870 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 880 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 890 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 901 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 911 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 921 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 931 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 942 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 952 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 962 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 972 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 983 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 993 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.0 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.0 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.2 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.2 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.3 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.3 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.3 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.3 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.4 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.4 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.5 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.5 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.5 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.5 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.5 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.6 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 16.3 MB/s \n",
            "\u001b[?25hSetup complete. Using torch 1.13.0+cu116 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
          ]
        }
      ],
      "source": [
        "# install dependencies as necessary\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)\n",
        "import torch\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "from utils.downloads import attempt_download  # to download models/datasets\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Knxi2ncxWffW",
        "outputId": "788f1146-bd82-46df-ef14-034cd09bafb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-0.2.21-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 933 kB/s \n",
            "\u001b[?25hCollecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (6.0)\n",
            "Collecting urllib3==1.26.6\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 30.6 MB/s \n",
            "\u001b[?25hCollecting chardet==4.0.0\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless>=4.5.1.48 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from roboflow) (4.64.1)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (from roboflow) (0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.4.4)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.15.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 7.7 MB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from roboflow) (3.2.2)\n",
            "Collecting certifi==2021.5.30\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from roboflow) (1.21.6)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->roboflow) (2.1.1)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=9854e9b24cc6892906d9a59950281b24c4a98d157e2b918ba37d132b7261ab0c\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0\n",
            "Successfully built wget\n",
            "Installing collected packages: urllib3, certifi, requests, pyparsing, cycler, wget, requests-toolbelt, python-dotenv, chardet, roboflow\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2022.12.7\n",
            "    Uninstalling certifi-2022.12.7:\n",
            "      Successfully uninstalled certifi-2022.12.7\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "Successfully installed certifi-2021.5.30 chardet-4.0.0 cycler-0.10.0 pyparsing-2.4.7 python-dotenv-0.21.0 requests-2.28.1 requests-toolbelt-0.10.1 roboflow-0.2.21 urllib3-1.26.6 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "chardet",
                  "cycler",
                  "pyparsing",
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in Uav-11 to yolov5pytorch: 100% [151665101 / 151665101] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to Uav-11 in yolov5pytorch:: 100%|██████████| 14845/14845 [00:03<00:00, 4352.25it/s]\n"
          ]
        }
      ],
      "source": [
        "#follow the link below to get your download code from from Roboflow\n",
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"fXNvqJubpdjp1mf8IS6s\")\n",
        "project = rf.workspace(\"detection-axsgy\").project(\"uav-ce0zg\")\n",
        "dataset = project.version(11).download(\"yolov5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug_PhK1oqwQA",
        "outputId": "0ae08ac8-258d-43cb-a36e-9bfd5ea3a626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "names:\n",
            "- Bird\n",
            "- Drone\n",
            "nc: 2\n",
            "roboflow:\n",
            "  license: CC BY 4.0\n",
            "  project: uav-ce0zg\n",
            "  url: https://universe.roboflow.com/detection-axsgy/uav-ce0zg/dataset/11\n",
            "  version: 11\n",
            "  workspace: detection-axsgy\n",
            "test: ../test/images\n",
            "train: Uav-11/train/images\n",
            "val: Uav-11/valid/images\n"
          ]
        }
      ],
      "source": [
        "%cd /content/yolov5\n",
        "%cat {dataset.location}/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOPn9wjOAwwK"
      },
      "outputs": [],
      "source": [
        "# define number of classes based on YAML\n",
        "import yaml\n",
        "with open(dataset.location + \"/data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rvt5wilnDyX",
        "outputId": "0063391c-c56d-438f-8265-5cb1beb9a25f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ],
      "source": [
        "#this is the model configuration we will use for our tutorial\n",
        "%cat //content/yolov5/models/yolov5s.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t14hhyqdmw6O"
      },
      "outputs": [],
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDxebz13RdRA"
      },
      "outputs": [],
      "source": [
        "%%writetemplate /content/yolov5/models/MFNet_small2.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "#Anchor boxes are a set of predefined bounding boxes of a certain height and width. These boxes are defined to capture the scale and\n",
        "#aspect ratio of specific object classes you want to detect and are typically chosen based on object sizes in your training datasets\n",
        "# anchors\n",
        "anchors: 3  # AutoAnchor evolves 3 anchors per P output layer\n",
        "#anchors:\n",
        "#  - [10,13, 16,30, 33,23]  # P3/8\n",
        "#  - [30,61, 62,45, 59,119]  # P4/16\n",
        "#  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone - feature extraction\n",
        "#Backbone: A convolutional neural network that aggregates and forms image features at different granularities\n",
        "#uses CSPDarkNet-53 as the backbone for extracting features from the input images. The backbone has five residual block modules,\n",
        "#and the feature map outputs from the residual block modules are fused at the neck.\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
        "  # Standard convolution with args (ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   # CSP:  ch_in, ch_out, number, shortcut, groups, expansion\n",
        "   [-1, 3, C3, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 6, C3, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, C3, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 3, C3, [1024]],\n",
        "#Neck: PANet+SPP- feature fusion\n",
        "#The neck connects the backbone and the head. It is composed of a spatial pyramid pooling (SPP) module and a path aggregation network (PAN).\n",
        "#The neck concatenates the feature maps from different layers of the backbone network and sends them as inputs to the head.\n",
        "\n",
        "#The SPP module in the neck concatenates the max-pooling outputs of the low-resolution feature map to extract the most representative\n",
        "#features. The SPP module uses kernels of size 1-by-1, 5-by-5, 9-by-9, and 13-by-13 for the max-pooling operation.\n",
        "#The stride value is set to 1. Concatenating the feature maps increases the receptive field (feature center location+size) of backbone features and\n",
        "#increases the accuracy of the network for detecting small objects. The concatenated feature maps from the SPP module are\n",
        "#fused with the high-resolution feature maps by using a PAN. The PAN uses upsampling and downsampling operations to set bottom-up\n",
        "#and top-down paths for combining the low-level and high-level features.\n",
        "#Spatial Pyramid Pooling (SPP) is a pooling layer that removes the fixed-size constraint of the network, i.e. a CNN does\n",
        "#not require a fixed-size input image\n",
        "##c1, c2, k=(5, 9, 13)\n",
        "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
        "  ]\n",
        "#The head processes the aggregated features and predicts the bounding boxes, objectness scores, and classification scores\n",
        "head:\n",
        "#The PAN module outputs a set of aggregated feature maps to use for predictions. YOLO network has three detection heads.\n",
        "#Each detection head is a YOLO v3 network that computes the final predictions. YOLO outputs feature maps of sizes 19-by-19, 38-by-38,\n",
        "#and 76-by-76 to predict the bounding boxes, classification scores, and objectness scores.\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, C3, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
        "#Head: Yolo Layer\n",
        "#Yolo Layer outputs detection results (class, score, location, size).\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "outputs": [],
      "source": [
        "# train model for first time\n",
        "#%%time\n",
        "#%cd /content/yolov5/\n",
        "#!python train.py --img 320 --batch-size -1 --epochs 600 --seed 1 --data {dataset.location}/data.yaml --cfg ./models/MFNet_small2.yaml --hyp data/hyps/hyp.scratch-high.yaml --weights '' --project \"/content/gdrive/MyDrive/Runs\"  --name MFNet_small2_results  --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsGKXBg2R_i4",
        "outputId": "f8886353-ee46-4d76-cbd4-f960f91a130e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=, data=data/coco128.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=300, batch_size=16, imgsz=320, rect=False, resume=/content/gdrive/MyDrive/Runs/MFNet_small2_results/weights/last.pt, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/gdrive/MyDrive/Runs, name=MFNet-small2_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 417 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "Resuming training from /content/gdrive/MyDrive/Runs/MFNet_small2_results/weights/last.pt\n",
            "YOLOv5 🚀 v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.1\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 🚀 runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/gdrive/MyDrive/Runs', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 161MB/s]\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1     14080  models.common.Focus                     [3, 128, 3]                   \n",
            "  1                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            "  2                -1  1     24000  models.common.BottleneckCSP             [128, 64, 1]                  \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  5                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            "  6                -1  3    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  7                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            "  8                -1  1     41344  models.common.SPP                       [128, 128, [5, 9, 13]]        \n",
            "  9                -1  1     78720  models.common.BottleneckCSP             [128, 128, 1, False]          \n",
            " 10                -1  1    204928  models.common.Conv                      [128, 64, 5, 1]               \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1     28096  models.common.BottleneckCSP             [192, 64, 1, False]           \n",
            " 14                -1  1    102528  models.common.Conv                      [64, 64, 5, 1]                \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     28096  models.common.BottleneckCSP             [192, 64, 1, False]           \n",
            " 18                -1  1    102528  models.common.Conv                      [64, 64, 5, 2]                \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1     24000  models.common.BottleneckCSP             [128, 64, 1, False]           \n",
            " 21                -1  1    102528  models.common.Conv                      [64, 64, 5, 2]                \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1     24000  models.common.BottleneckCSP             [128, 64, 1, False]           \n",
            " 24      [17, 20, 23]  1      4095  models.yolo.Detect                      [2, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [64, 64, 64]]\n",
            "Model summary: 283 layers, 1618367 parameters, 1618367 gradients, 17.5 GFLOPs\n",
            "\n",
            "Transferred 369/369 items from /content/gdrive/MyDrive/Runs/MFNet_small2_results/weights/last.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for --imgsz 320\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.76G total, 0.03G reserved, 0.01G allocated, 14.71G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "     1618367       4.371         0.944         128.7         85.27        (1, 3, 320, 320)                    list\n",
            "     1618367       8.743         1.040         17.93         78.53        (2, 3, 320, 320)                    list\n",
            "     1618367       17.49         1.197         20.21         96.71        (4, 3, 320, 320)                    list\n",
            "     1618367       34.97         1.512         19.03         112.4        (8, 3, 320, 320)                    list\n",
            "     1618367       69.94         2.221         22.58         164.4       (16, 3, 320, 320)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 146 for CUDA:0 13.20G/14.76G (89%) ✅\n",
            "Scaled weight_decay = 0.001140625\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 59 weight (no decay), 70 weight, 62 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5/Uav-11/train/labels' images and labels...7053 found, 0 missing, 0 empty, 0 corrupt: 100% 7053/7053 [00:03<00:00, 2081.56it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/Uav-11/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (2.2GB ram): 100% 7053/7053 [00:11<00:00, 631.30it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/Uav-11/valid/labels' images and labels...365 found, 0 missing, 0 empty, 0 corrupt: 100% 365/365 [00:00<00:00, 778.36it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/Uav-11/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 365/365 [00:01<00:00, 272.67it/s]\n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/gdrive/MyDrive/Runs/MFNet_small2_results\u001b[0m\n",
            "Starting training for 600 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   319/599     10.2G   0.03089  0.008456  0.001707       114       320: 100% 49/49 [00:47<00:00,  1.03it/s]\n",
            "               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 2/2 [00:09<00:00,  4.73s/it]\n",
            "                 all        365        365        171        7.5      0.955      0.932      0.943      0.955      0.646\n",
            "                Bird        365        242        229          8      0.966      0.944      0.955      0.972      0.662\n",
            "               Drone        365        123        113          7      0.945      0.919      0.931      0.938       0.63\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   320/599     10.1G   0.03067  0.008478  0.001678       134       320: 100% 49/49 [00:36<00:00,  1.33it/s]\n",
            "               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.29s/it]\n",
            "                 all        365        365        170        7.5      0.955      0.931      0.942      0.955      0.648\n",
            "                Bird        365        242        228          8      0.966      0.942      0.954      0.972      0.664\n",
            "               Drone        365        123        113          7      0.943      0.919      0.931      0.938      0.631\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   321/599     10.1G   0.03223  0.008858  0.002117       142       320: 100% 49/49 [00:37<00:00,  1.31it/s]\n",
            "               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.32s/it]\n",
            "                 all        365        365        171          6      0.961      0.932      0.947      0.955      0.647\n",
            "                Bird        365        242        228          6      0.972      0.942      0.957      0.973      0.665\n",
            "               Drone        365        123        114          6       0.95      0.923      0.936      0.938       0.63\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   322/599     10.1G   0.03244   0.00859  0.002122       122       320: 100% 49/49 [00:38<00:00,  1.27it/s]\n",
            "               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.25s/it]\n",
            "                 all        365        365        171        6.5       0.96      0.934      0.947      0.955      0.647\n",
            "                Bird        365        242        228          7      0.971      0.942      0.956      0.973      0.664\n",
            "               Drone        365        123        114          6       0.95      0.925      0.937      0.938      0.631\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   323/599     10.1G   0.03207  0.008715  0.002051       160       320: 100% 49/49 [00:38<00:00,  1.29it/s]\n",
            "               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.31s/it]\n",
            "                 all        365        365        172          6      0.963      0.936       0.95      0.956      0.648\n",
            "                Bird        365        242        229          6      0.977      0.946      0.961      0.974      0.664\n",
            "               Drone        365        123        114          6       0.95      0.926      0.938      0.938      0.632\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   324/599     10.1G   0.03242  0.008891   0.00209       166       320: 100% 49/49 [00:38<00:00,  1.28it/s]\n",
            "               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.22s/it]\n",
            "                 all        365        365        172        5.5      0.964      0.936      0.949      0.956      0.647\n",
            "                Bird        365        242        229          5      0.977      0.946      0.962      0.975      0.663\n",
            "               Drone        365        123        114          6       0.95      0.925      0.937      0.938      0.631\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   325/599     10.1G   0.03205  0.008605  0.002002       119       320: 100% 49/49 [00:38<00:00,  1.28it/s]\n",
            "               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.33s/it]\n",
            "                 all        365        365        172        5.5      0.964      0.936       0.95      0.956      0.647\n",
            "                Bird        365        242        229          5      0.978      0.946      0.962      0.975      0.664\n",
            "               Drone        365        123        114          6       0.95      0.925      0.937      0.938       0.63\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   326/599     10.1G   0.03225  0.008638  0.002011       118       320: 100% 49/49 [00:43<00:00,  1.13it/s]\n",
            "               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.14s/it]\n",
            "                 all        365        365        172        5.5      0.964      0.935       0.95      0.957      0.648\n",
            "                Bird        365        242        229          5      0.979      0.946      0.962      0.975      0.666\n",
            "               Drone        365        123        114          6       0.95      0.925      0.937      0.938       0.63\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   327/599     10.1G   0.03185  0.008819  0.002054       134       320: 100% 49/49 [00:38<00:00,  1.27it/s]\n",
            "               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.33s/it]\n",
            "                 all        365        365        172        5.5      0.964      0.935      0.949      0.956      0.648\n",
            "                Bird        365        242        229          5      0.978      0.946      0.962      0.975      0.666\n",
            "               Drone        365        123        114          6       0.95      0.924      0.937      0.938      0.629\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   328/599     10.1G   0.03206  0.008761  0.002051       130       320: 100% 49/49 [00:38<00:00,  1.27it/s]\n",
            "               Class     Images     Labels         TP         FP          P          R         F1     mAP@.5 mAP@.5:.95: 100% 2/2 [00:04<00:00,  2.27s/it]\n",
            "                 all        365        365        172        5.5      0.964      0.936       0.95      0.957      0.649\n",
            "                Bird        365        242        229          5      0.978      0.946      0.962      0.975      0.667\n",
            "               Drone        365        123        114          6       0.95      0.925      0.937      0.938      0.631\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "   329/599     10.1G   0.03166  0.008512  0.002135       409       320:  73% 36/49 [00:28<00:11,  1.14it/s]"
          ]
        }
      ],
      "source": [
        "#Later, if it is stopped prematurely and I need to resume, I use\n",
        "!python train.py --img 320 --weights '' --project \"/content/gdrive/MyDrive/Runs\"  --name MFNet-small2_results  --cache  --resume \"/content/gdrive/MyDrive/Runs/MFNet_small2_results/weights/last.pt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KUR8mCvN56z"
      },
      "outputs": [],
      "source": [
        "%cd /content/yolov5/\n",
        "!python detect.py --weights /content/gdrive/MyDrive/Runs/MFNet_small2_results/weights/best.pt --img 320 --conf 0.3 --source /content/yolov5/Uav-7/valid/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyIzk2RdN8m-"
      },
      "outputs": [],
      "source": [
        "!python val.py --task study --weights /content/gdrive/MyDrive/Runs/MFNet_small2_results/weights/best.pt --data {dataset.location}/data.yaml --iou 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfgm08h-N99T"
      },
      "outputs": [],
      "source": [
        "!python val.py --task speed --weights /content/gdrive/MyDrive/Runs/MFNet_small2_results/weights/best.pt--data {dataset.location}/data.yaml --iou 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFajrUvwN_g2"
      },
      "outputs": [],
      "source": [
        "!python val.py --img 320 --weights /content/gdrive/MyDrive/Runs/MFNet_small2_results/weights/best.pt --data {dataset.location}/data.yaml --iou 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nmZZnWOgJ2S"
      },
      "outputs": [],
      "source": [
        "#%cd /content/yolov5/\n",
        "#!python detect.py --weights runs/train/MFNet_small2_results/weights/best.pt --img 320 --conf 0.3 --source /content/yolov5/Uav-7/valid/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl889R_TOVq5"
      },
      "outputs": [],
      "source": [
        "#### Visulize each layers feature map\n",
        "#######Run this cell to know the whats inside every lare feature\n",
        "#### stop it ur self after one image is done\n",
        "## Print whole folder feature maps and save them\n",
        "#!python detect.py --weights /content/yolov5/mfnets.pt --img 416 --conf 0.4 --source /content/yolov5/Uav-7/test/images --visualize\n",
        "####### Only single image\n",
        "#!python detect.py --weights /content/yolov5/mfnets.pt --img 416 --conf 0.4 --source /content/yolov5/Uav-7/test/images/0094_jpg.rf.09856e96b7f9f77c2bc502452ec20d77.jpg --visualize\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW_l5cj79CCQ"
      },
      "outputs": [],
      "source": [
        "#!python val.py --task study --weights runs/train/MFNet_small2_results2/weights/best.pt --data {dataset.location}/data.yaml --iou 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deVrymet94yx"
      },
      "outputs": [],
      "source": [
        "#!python val.py --task speed --weights runs/train/MFNet_small2_results2/weights/best.pt--data {dataset.location}/data.yaml --iou 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t-Ag_TEXN-6"
      },
      "outputs": [],
      "source": [
        "#!python val.py --img 320 --weights runs/train/MFNet_small2_results2/weights/best.pt --data {dataset.location}/data.yaml --iou 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AaC0FNlXPzT"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/MFNet_small2.zip /content/gdrive/MyDrive/Runs/\n",
        "!zip -r /content/MFNet_small2.zip /content/yolov5/runs/\n",
        "from google.colab import files\n",
        "files.download(\"/content/MFNet_small2.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}